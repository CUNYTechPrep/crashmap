{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor Vehicle Collision Data ETL Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to import the needed modules and functions. `numpy`, `pandas`, and `toolz` may need to be installed if you do not already have them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from toolz import compose_left as compose\n",
    "\n",
    "escape = partial(re.compile(r'\\'').sub, r'\\'\\'')\n",
    "\n",
    "make_postgresql_array_literal = compose(pd.Series.dropna,\n",
    "                                        partial(map, compose(escape, '\\'{}\\''.format)),\n",
    "                                        ', '.join,\n",
    "                                        '{{{}}}'.format,\n",
    "                                        lambda result: np.nan\n",
    "                                                       if result == '{}'\n",
    "                                                       else result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to query the NYC OpenData servers for the data. The query is written so that it extracts *only* the required columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = {'c': pd.read_csv(\"https://data.cityofnewyork.us/resource/h9gi-nx95.csv?$select=collision_id,crash_date,crash_time,latitude,longitude&$where=crash_date%20between%20'2020-01-01'%20and%20'2020-01-31'&$limit=100000\", dtype='str'),\n",
    "               'v': pd.read_csv(\"https://data.cityofnewyork.us/resource/bm4k-52h4.csv?$select=unique_id,collision_id,state_registration,vehicle_type,vehicle_make,vehicle_model,vehicle_year,travel_direction,vehicle_occupants,driver_sex,driver_license_status,driver_license_jurisdiction,pre_crash,point_of_impact,vehicle_damage_1,vehicle_damage_2,vehicle_damage_3,public_property_damage,public_property_damage_type,contributing_factor_1,contributing_factor_2&$where=crash_date%20between%20'2020-01-01'%20and%20'2020-01-31'&$limit=100000\", dtype='str'),\n",
    "               'p': pd.read_csv(\"https://data.cityofnewyork.us/resource/f55k-p6yu.csv?$select=unique_id,collision_id,vehicle_id,person_type,person_injury,person_age,ejection,emotional_status,bodily_injury,position_in_vehicle,safety_equipment,ped_location,ped_action,complaint,ped_role,contributing_factor_1,contributing_factor_2,person_sex&$where=crash_date%20between%20'2020-01-01'%20and%20'2020-01-31'&$limit=100000\", dtype='str')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below cell again to get a fresh copy of the data frames without hitting the servers again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = data_frames['c'].copy(deep=True)\n",
    "v = data_frames['v'].copy(deep=True)\n",
    "p = data_frames['p'].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to transform the data frames. Some statements change the column names and some aggregate them horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.rename(columns=dict(zip('collision_id,crash_date,crash_time,latitude,longitude'.split(','),\n",
    "                              'id,date,time,latitude,longitude'.split(','))))\n",
    "c = c.set_index('id')\n",
    "c.fillna('\\\\N', inplace=True)\n",
    "\n",
    "v = v.rename(columns=dict(zip('unique_id,collision_id,state_registration,vehicle_type,vehicle_make,vehicle_model,vehicle_year,travel_direction,vehicle_occupants,driver_sex,driver_license_status,driver_license_jurisdiction,pre_crash,point_of_impact,vehicle_damage_1,vehicle_damage_2,vehicle_damage_3,public_property_damage,public_property_damage_type,contributing_factor_1,contributing_factor_2'.split(','),\n",
    "                              'id,collision_id,state_registration,type,make,model,year,travel_direction,occupants,driver_sex,driver_license_status,driver_license_jurisdiction,pre_crash,point_of_impact,damage_1,damage_2,damage_3,public_property_damage,public_property_damage_type,contributing_factor_1,contributing_factor_2'.split(','))))\n",
    "v = v.set_index('id')\n",
    "v['damage_1'] = v.get(['damage_1', 'damage_2', 'damage_3']) \\\n",
    "                 .agg(make_postgresql_array_literal, axis=1)\n",
    "v.rename(columns={'damage_1': 'damages'}, inplace=True)\n",
    "v.drop(columns=['damage_2', 'damage_3'], inplace=True)\n",
    "\n",
    "v['contributing_factor_1'] = v.get(['contributing_factor_1', 'contributing_factor_2']) \\\n",
    "                              .agg(make_postgresql_array_literal, axis=1)\n",
    "v.rename(columns={'contributing_factor_1': 'contributing_factors'}, inplace=True)\n",
    "v.drop(columns=['contributing_factor_2'], inplace=True)\n",
    "v.fillna('\\\\N', inplace=True)\n",
    "\n",
    "p = p.rename(columns=dict(zip('unique_id,collision_id,vehicle_id,person_type,person_injury,person_age,ejection,emotional_status,bodily_injury,position_in_vehicle,safety_equipment,ped_location,ped_action,complaint,ped_role,contributing_factor_1,contributing_factor_2,person_sex'.split(','),\n",
    "                              'id,collision_id,vehicle_id,type,injury,age,ejection,emotional_status,bodily_injury,position_in_vehicle,safety_equipment,location,action,complaint,role,contributing_factor_1,contributing_factor_2,sex'.split(','))))\n",
    "p = p.set_index('id')\n",
    "p['contributing_factor_1'] = p.get(['contributing_factor_1', 'contributing_factor_2']) \\\n",
    "                              .agg(make_postgresql_array_literal, axis=1)\n",
    "p.rename(columns={'contributing_factor_1': 'contributing_factors'}, inplace=True)\n",
    "p.drop(columns=['contributing_factor_2'], inplace=True)\n",
    "p.insert(p.columns.get_loc('vehicle_id') + 1, 'dangling_vehicle_id', np.where(p.vehicle_id.isin(v.index), np.nan, p.vehicle_id))\n",
    "p['vehicle_id'] = np.where(p.vehicle_id.isin(v.index), p.vehicle_id, np.nan)\n",
    "p.fillna('\\\\N', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cells below to copy the results to the clipboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.to_clipboard()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
